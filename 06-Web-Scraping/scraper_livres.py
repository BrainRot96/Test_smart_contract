import requests 
from bs4 import BeautifulSoup
import csv 

print("=== SCRAPER DE LIVRES ===\n")

url = "http://books.toscrape.com/"
responses = requests.get(url)

if responses.status_code == 200:
    print("âœ… ConnectÃ© au site de livres !\n")
    soup = BeautifulSoup(responses.text, 'html.parser')
else:
   print("âŒ Erreur de connexion")
   exit()

livres = soup.find_all('article', class_='product_pod')

print(f"TrouvÃ© {len(livres)} livres\n")

liste_livres = []
for livre in livres[:10]:
    titre_tag = livre.find('h3').find('a')
    titre = titre_tag['title']

    prix = livre.find('p', class_='price_color').text

    note_tag = livre.find('p', class_='star-rating')
    note = note_tag['class'][1]

    print(f"ğŸ“š {titre}")
    print(f"   ğŸ’° Prix : {prix}")
    print(f"   â­ Note : {note}")
    print()

    liste_livres.append({
        'titre': titre,
        'prix': prix,
        'note': note
    })

print(f"âœ… {len(liste_livres)} livres extraits !")

nom_fichier = "livres.csv"

with open(nom_fichier, 'w', newline='', encoding='utf-8') as f:
    writer = csv.DictWriter(f, fieldnames=['titre', 'prix', 'note'])

    writer.writeheader()

    writer.writerows(liste_livres)

print(f"\nğŸ’¾ DonnÃ©es sauvegardÃ©es dans {nom_fichier} !")
